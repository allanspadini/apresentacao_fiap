---
title: "&#8203;"
title-slide-attributes:
    data-background-image: imgs/title.png
    data-background-size: contain
    data-background-opacity: "1.0"
author: "&#8203;"
format: 
    revealjs:
        theme: [default, custom.scss]
        transition: fade
        slide-number: true
        preview-links: true
        incremental: true
        embed-resources: false
        notes: false
        self-contained-math: true
---

## ‚Äã

::: column-screen-inset
<iframe src="imgs/apresentacao.html" width="2000px" height="600px">

</iframe>
:::

## Pergunta

**Machine learning** e **deep learning** ainda s√£o relevantes na era das LLMs?

![](imgs/duvida.jpg)

::: notes
Para come√ßar essa apresenta√ß√£o eu vou come√ßar com uma pergunta. **Machine learning** e **deep learning** ainda s√£o relevantes na era das LLMs? Pra responder essa pergunta vamos partir do zero. Eu n√£o vou contar a hist√≥ria do machine learning aqui, mas n√≥s vamos entender qual a categoriza√ß√£o dessas coisas e que tipo de problemas que elas s√£o capazes de resolver.
:::

## Qual a organiza√ß√£o?

![](imgs/sequencia.svg){fig-align="center",width=270}

::: notes
O termo IA explodiu nos √∫ltimos anos e quando as pessoas est√£o falando de LLMs ou de IA generativa no geral elas utilizam o termo IA. Mas na pr√°tica intelig√™ncia artificial √© uma √°rea bem abrangente que engloba o machine learning, dentro do machine learning n√≥s m√©todos espec√≠ficos que envolvem redes neurais e como consequ√™ncia o deep learning. E as LLMs e geradores de imagem no geral s√£o modelos de deep learning treinados com um prop√≥sito espec√≠fico. Embora hoje em dia com uso de ferramentas, agentes e mem√≥ria e racioc√≠nio estejam tentando imitar o que seria o comportamento de uma IA uma intelig√™ncia artifical mais geral.
:::

## O que √© o machine learning?

| Renda Mensal (R\$) | Tempo de Relacionamento (meses) | Risco de Inadimpl√™ncia |
|-------------------|------------------------------|-----------------------|
| 2.500              | 8                               | Alto                   |
| 4.800              | 36                              | Baixo                  |
| 3.200              | 12                              | M√©dio                  |
| 8.500              | 60                              | Baixo                  |
| 1.800              | 3                               | Alto                   |
| 5.300              | 24                              | Baixo                  |

::: notes
Mas a ess√™ncia de tudo √© o machine learning. No machine learning n√≥s utilizamos t√©cnicas que permitem que os computadores aprendam sem serem explicitamente programados. Por exemplo, eu n√£o tenho uma regra pr√© definida que eu consiga aplicar pra resolver o problema dessa tabela de me dizer se o risco de inadinpl√™ncia de um cliente de um banco √© alto ou baixo. Por√©m, existem algoritmos que se eu passar cada um desses exemplos eles v√£o ser capazes de come√ßar a identificar padr√µes e posteriormente fazer a classifica√ß√£o dos clientes quando passar um cliente novo. Ou seja, o algoritmo n√£o apenas memorizar esses exemplos, mas tamb√©m vai generalizar de forma que quando eu passar um exemplo novo de clientes que tem caracter√≠sticas um pouquinho diferentes ele tamb√©m vai conseguir classificar os clientes.
:::

## Subdivis√µes do Machine learning

-   Aprendizado supervisionado

-   Aprendizado n√£o-supervisionado

-   Aprendizagem por refor√ßo

::: notes
E o machine learning pode ser subdividido em tr√™s categorias principais que seriam o Aprendizado supervisionado, Aprendizado n√£o-supervisionado, Aprendizagem por refor√ßo.
:::

------------------------------------------------------------------------

## Aprendizado supervisionado

::: column-screen-inset
<iframe src="imgs/supervisionado.html" width="2000px" height="600px">

</iframe>
:::

::: notes
No aprendizado supervisionado n√≥s temos ainda a regress√£o e a classifica√ß√£o. Na regress√£o o objetivo √© prever um valor cont√≠nuo e na classifica√ß√£o separar as classes como no exemplo que eu j√° citei.
:::

## Regress√£o {auto-animate="true"}

```{python}
import numpy as np
import pandas as pd
import plotly.express as px

# Par√¢metros
np.random.seed(42)
meses = pd.date_range(start='2022-01-01', end='2024-12-01', freq='MS')
n = len(meses)

# Tend√™ncia de crescimento linear
tendencia = np.linspace(10000, 40000, n)

# Sazonalidade anual (picos em dezembro)
sazonalidade = 5000 * np.sin(2 * np.pi * (meses.month - 1) / 12)

# Ru√≠do aleat√≥rio
ruido = np.random.normal(0, 1500, n)

# Receita simulada
receita = tendencia + sazonalidade + ruido

# DataFrame
df = pd.DataFrame({
    'M√™s': meses,
    'Receita Mensal (R$)': receita
})

# Gr√°fico
fig = px.scatter(df, x='M√™s', y='Receita Mensal (R$)', 
                 title='Receita Mensal de uma Loja Online (2022-2024)',
                 labels={'Receita Mensal (R$)': 'Receita Mensal (R$)'},
                 )

fig.update_traces(marker=dict(size=8, color='royalblue'))
fig.show()


```

::: notes
E a√≠ a regress√£o √© um √≥timo ponto de partida pra que n√≥s possamos come√ßar a entender como funciona a generaliza√ß√£o de um m√©todo de machine learning. Vamos pegar esse exemplo onde queremos em um dia x intermedi√°rio entre dezembro e janeiro de 2023.
:::

## Regress√£o {auto-animate="true"}

```{python}
import numpy as np
import pandas as pd
import plotly.express as px

# Par√¢metros
np.random.seed(42)
meses = pd.date_range(start='2022-01-01', end='2024-12-01', freq='MS')
n = len(meses)

# Tend√™ncia de crescimento linear
tendencia = np.linspace(10000, 40000, n)

# Sazonalidade anual (picos em dezembro)
sazonalidade = 5000 * np.sin(2 * np.pi * (meses.month - 1) / 12)

# Ru√≠do aleat√≥rio
ruido = np.random.normal(0, 1500, n)

# Receita simulada
receita = tendencia + sazonalidade + ruido

# DataFrame
df = pd.DataFrame({
    'M√™s': meses,
    'Receita Mensal (R$)': receita
})

# Gr√°fico
fig = px.scatter(df, x='M√™s', y='Receita Mensal (R$)', 
                 title='Receita Mensal de uma Loja Online (2022-2024)',
                 labels={'Receita Mensal (R$)': 'Receita Mensal (R$)'},
                 trendline="ols")

fig.update_traces(marker=dict(size=8, color='royalblue'))
for trace in fig.data:
    if trace.mode == 'lines':
        trace.line.color = 'red'
fig.show()


```

::: notes
Pra fazer isso eu posso muito bem ajustar uma reta a esses dados.
:::

## Regress√£o

::: fragment
$$
y = a \cdot x +b 
$$
:::

::: fragment
$$
y = 0.00028 \cdot x -452196 
$$
:::

::: notes
Quando eu ajusto uma reta aos dados eu estou calculando os coeficientes dessa reta. De forma que tendo os coeficientes eu consigo fazer uma estimativa dos valores intermedi√°rios ou at√© uma tentativa de extrapola√ß√£o fazendo uma proje√ß√£o da reta para o futuro. J√° que nesse caso nos estamos com um caso particular de regress√£o que envolve uma s√©rie temporal. Ou seja, ajustando a reta e determinando os coeficientes estamos conseguindo generalizar o problema e calcular o valor da receita mesmo em datas onde n√£o coletamos o valor da receita.
:::

## Regress√£o

```{python}
import numpy as np
import pandas as pd
import plotly.graph_objects as go

# Par√¢metros
np.random.seed(42)
meses = pd.date_range(start='2022-01-01', end='2024-12-01', freq='MS')
n = len(meses)

# Tend√™ncia de crescimento linear
tendencia = np.linspace(10000, 40000, n)

# Sazonalidade anual (picos em dezembro)
sazonalidade = 5000 * np.sin(2 * np.pi * (meses.month - 1) / 12)

# Ru√≠do aleat√≥rio
ruido = np.random.normal(0, 1500, n)

# Receita simulada
receita = tendencia + sazonalidade + ruido

# DataFrame
df = pd.DataFrame({
    'M√™s': meses,
    'Receita Mensal (R$)': receita
})

# Transformando a data em n√∫mero para ajuste polinomial
x = np.arange(n)  # pode ser dias ou meses, aqui estamos usando a posi√ß√£o do m√™s
y = receita

# Ajuste polinomial de grau 4 (voc√™ pode mudar para 3, 5, etc)
grau = 9
coef = np.polyfit(x, y, grau)
polinomio = np.poly1d(coef)

# Valores ajustados pelo polin√¥mio
y_fit = polinomio(x)

# Gr√°fico
fig = go.Figure()

# Pontos reais
fig.add_trace(go.Scatter(
    x=df['M√™s'], y=y, mode='markers',
    marker=dict(size=8, color='royalblue'),
    name='Receita Mensal'
))

# Curva polinomial ajustada
fig.add_trace(go.Scatter(
    x=df['M√™s'], y=y_fit, mode='lines',
    line=dict(color='red', width=3),
    name=f'Ajuste Polinomial (grau {grau})'
))

fig.update_layout(
    title='Receita Mensal de uma Loja Online (2022-2024) com Ajuste Polinomial',
    xaxis_title='M√™s',
    yaxis_title='Receita Mensal (R$)'
)

fig.show()

```

::: notes
√â claro que podemos ver que a reta talvez n√£o seja a melhor solu√ß√£o para esse caso. Poderia ajustar um polin√¥mio talvez.
:::

## Classifica√ß√£o

```{python}
import numpy as np
import pandas as pd
import plotly.express as px

np.random.seed(42)
n = 100
desconto = np.random.uniform(0, 50, n)

def sigmoid(x):
    return 1 / (1 + np.exp(-(x-25)/5))

prob_compra = sigmoid(desconto)
classe = np.random.binomial(1, prob_compra)

df = pd.DataFrame({'Desconto (%)': desconto, 'Comprou': classe})

# Converta a coluna para string para garantir que seja categ√≥rica
df['Comprou'] = df['Comprou'].astype(str)

fig = px.scatter(
    df, x='Desconto (%)', y='Comprou',
    color='Comprou',
    color_discrete_map={'0': 'red', '1': 'blue'},
    category_orders={'Comprou': ['1', '0']},  # Ordem correta: 0 embaixo, 1 em cima
    title='Probabilidade de Compra em Fun√ß√£o do Desconto',
    labels={'Comprou': 'Classe (0=N√£o comprou, 1=Comprou)'}
)

fig.update_traces(marker=dict(size=10, opacity=0.7, line=dict(width=1, color='black')))

fig.show()


```

::: notes
J√° a classifica√ß√£o em um primeiro momento √© um pouco mais dif√≠cil de pensar como um ajuste de curva aos dados porque estamos tentando separar duas classes diferentes.
:::

## Classifica√ß√£o

```{python}
import numpy as np
import pandas as pd
import plotly.express as px

np.random.seed(42)
n = 100
desconto = np.random.uniform(0, 50, n)

def sigmoid(x):
    return 1 / (1 + np.exp(-(x-25)/5))

prob_compra = sigmoid(desconto)
classe = np.random.binomial(1, prob_compra)

df = pd.DataFrame({'Desconto (%)': desconto, 'Comprou': classe})

fig = px.scatter(
    df, x='Desconto (%)', y='Comprou',
    color=df['Comprou'].astype(str),
    color_discrete_map={'0': 'red', '1': 'blue'},
    title='Probabilidade de Compra em Fun√ß√£o do Desconto',
    labels={'Comprou': 'Classe (0=N√£o comprou, 1=Comprou)'}
)
fig.update_traces(marker=dict(size=10, opacity=0.7, line=dict(width=1, color='black')))

# Adicionando a curva sigmoide
x_curve = np.linspace(0, 50, 200)
y_curve = sigmoid(x_curve)

fig.add_scatter(
    x=x_curve,
    y=y_curve,
    mode='lines',
    name='Curva Sigmoide',
    line=dict(color='black', width=3)
)

fig.show()



```

::: notes
Mas tamb√©m podemos ver o problema dessa forma. Nesse caso por exemplo podemos ajustar uma curva do tipo sigm√≥ide.
:::

## Classifica√ß√£o

```{python}
import numpy as np
import pandas as pd
import plotly.express as px

np.random.seed(42)
n = 100
desconto = np.random.uniform(0, 50, n)

def sigmoid(x):
    return 1 / (1 + np.exp(-(x-25)/5))

prob_compra = sigmoid(desconto)
classe = np.random.binomial(1, prob_compra)

df = pd.DataFrame({'Desconto (%)': desconto, 'Comprou': classe})

fig = px.scatter(
    df, x='Desconto (%)', y='Comprou',
    color=df['Comprou'].astype(str),
    color_discrete_map={'0': 'red', '1': 'blue'},
    title='Probabilidade de Compra em Fun√ß√£o do Desconto',
    labels={'Comprou': 'Classe (0=N√£o comprou, 1=Comprou)'}
)
fig.update_traces(marker=dict(size=10, opacity=0.7, line=dict(width=1, color='black')))

# Adicionando a curva sigmoide
x_curve = np.linspace(0, 50, 200)
y_curve = sigmoid(x_curve)

fig.add_scatter(
    x=x_curve,
    y=y_curve,
    mode='lines',
    name='Curva Sigmoide',
    line=dict(color='black', width=3)
)

# Adicionando a linha divis√≥ria em y=0.5
fig.add_shape(
    type="line",
    x0=0, x1=50,
    y0=0.5, y1=0.5,
    line=dict(color="green", width=2, dash="dash"),
    name='Divis√£o 0.5'
)

# Opcional: adicionar anota√ß√£o indicando o limiar
fig.add_annotation(
    x=2, y=0.52,
    text="Limiar 0.5",
    showarrow=False,
    font=dict(color="green", size=12),
    bgcolor="white"
)

fig.show()

```

::: notes
e depois definir em que n√≠vel de diferen√ßa dos valores da sigm√≥ide vamos separar os dados.
:::

## Classifica√ß√£o

$$ 
\sigma(\mathbf{x}) = \frac{1}{1 + e^{-(w^T \mathbf{x} + b)}}
$$

## Aprendizado supervisionado

[Scikit-learn](https://scikit-learn.org/stable/supervised_learning.html)

::: notes
√â claro que esses s√£o apenas alguns dos m√©todos dispon√≠veis para regress√£o e classifica√ß√£o se entrarmos por exemplo na p√°gina da sklearn vamos ver in√∫meros outros m√©todos que v√£o ser mais ou menos eficientes para se ajustar a tipos de dados diferentes de n tipos de problemas de regress√£o e classifica√ß√£o.
:::

## Aprendizado supervisionado

| Id  | Idade | IMC  | Glicose | Press√£o | Diabetes üéØ |
|-----|-------|------|---------|---------|-------------|
| 1   | 45    | 29.0 | 130     | 80      | ‚úÖ Sim      |
| 2   | 34    | 22.5 | 98      | 70      | ‚ùå N√£o      |
| 3   | 54    | 31.2 | 145     | 85      | ‚úÖ Sim      |
| 4   | 29    | 24.1 | 92      | 75      | ‚ùå N√£o      |
| 5   | 62    | 33.8 | 160     | 90      | ‚úÖ Sim      |

::: notes
Ainda nos problemas de apredizagem supervisionado, a caracter√≠stica mais importante √© que nesses problemas eu tenho um alvo. Por exemplo nesse caso eu tenho a classe se a pessoa tem ou n√£o diabetes, ou no problema financeiro de regress√£o eu tenho os valores monet√°rios para cada data. O que √© importante notar √© esses valores s√£o valores que aprenda de alguma forma a descobrir quando passo por exemplo as caracter√≠sticas do paciente ou do problema e pra que ele consiga aprender sobre o problema n√≥s precisamos ter esses valores registrados. Algu√©m precisou ir l√° entrevistar ou avaliar o caso de n pacientes e anotar os pacientes com as caracter√≠sticas x tem diabetes e os com as caracter√≠sticas y n√£o, depois os z tem...
:::

## Detec√ß√£o de fraude

![Rob√¥ cometendo fraude](imgs/fraude.png)

::: notes
Embora os dados tabulares sejam o exemplo mais simples de dados que n√≥s temos existem muitas aplica√ß√µes sobre esse tipo de dados. Um exemplo √© a detec√ß√£o de fraude. Modelos supervisionados (como Random Forest, XGBoost) treinados com hist√≥rico de transa√ß√µes rotuladas como ‚Äúfraudulentas‚Äù ou ‚Äúleg√≠timas‚Äù.
:::

## Previs√£o de churn

``` markdown
| customer_id | idade | tempo_de_contrato (meses) | valor_mensal | utilizacao_app (dias/m√™s) | reclamacoes | churn |
|-------------|-------|--------------------------|--------------|---------------------------|-------------|-------|
| 001         | 25    | 12                       | 79.90        | 22                        | 0           | 0     |
| 002         | 42    | 6                        | 99.90        | 10                        | 2           | 1     |
| 003         | 34    | 24                       | 59.90        | 25                        | 0           | 0     |
| 004         | 28    | 3                        | 89.90        | 5                         | 1           | 1     |
| 005         | 50    | 36                       | 49.90        | 30                        | 0           | 0     |
```

::: notes
Empresas de SaaS, telecom, bancos e varejo querem prever quais clientes est√£o propensos a cancelar seus servi√ßos.
:::

## Otimiza√ß√£o de cadeia de suprimentos

``` markdown
| produto_id | centro_distribuicao | estoque_atual | demanda_prevista | tempo_reposicao (dias) | custo_transporte | prioridade |
|------------|---------------------|---------------|------------------|-----------------------|------------------|------------|
| 1001       | SP                  | 150           | 200              | 2                     | 500              | 1          |
| 1002       | RJ                  | 80            | 60               | 3                     | 400              | 2          |
| 1003       | MG                  | 50            | 100              | 5                     | 700              | 1          |
| 1004       | RS                  | 200           | 180              | 4                     | 300              | 3          |
| 1005       | BA                  | 90            | 120              | 6                     | 600              | 2          |
```

::: notes
Previs√£o de demanda para estoques, log√≠stica e produ√ß√£o.
:::

## Aprendizado n√£o-supervisionado

| Id  | Idade | IMC  | Glicose | Press√£o |
|-----|-------|------|---------|---------|
| 1   | 45    | 29.0 | 130     | 80      |
| 2   | 34    | 22.5 | 98      | 70      |
| 3   | 54    | 31.2 | 145     | 85      |
| 4   | 29    | 24.1 | 92      | 75      |
| 5   | 62    | 33.8 | 160     | 90      |

::: notes
Mas eventualmente n√≥s nos deparamos com problemas que √© a primeira vez que n√≥s estamos vendo. N√≥s nem sequer sabemos que a diabetes existe, por exemplo. Mas a√≠ nos nossos registros m√©dicos vamos anotando os dados das pessoas e vamos percebendo algumas caracter√≠sticas.
:::

## Clustering

```{python}

import pandas as pd
import plotly.express as px
from sklearn.datasets import make_blobs

# Gerar dados sint√©ticos com 2 clusters
X, y = make_blobs(n_samples=100, centers=2, cluster_std=2.5, random_state=42)

# Ajustar os valores para simular IMC e Glicose em faixas realistas
# IMC: entre 18 e 40, Glicose: entre 70 e 200
IMC = 18 + (X[:, 0] - X[:, 0].min()) * (40 - 18) / (X[:, 0].max() - X[:, 0].min())
Glicose = 70 + (X[:, 1] - X[:, 1].min()) * (200 - 70) / (X[:, 1].max() - X[:, 1].min())

# Criar DataFrame
df = pd.DataFrame({
    'IMC': IMC,
    'Glicose': Glicose,
    'Grupo': ['Grupo 1' if label == 0 else 'Grupo 2' for label in y]
})

# Plot com Plotly
fig = px.scatter(
    df, x='IMC', y='Glicose',
    color='Grupo',
    title='Clustering Simulado: IMC vs Glicose',
    labels={'IMC': 'IMC', 'Glicose': 'Glicose'}
)
fig.show()



```

::: notes
E a√≠ um primeiro tipo de algoritmo bastanta conhecido seria um algoritmo de clustering e esse algoritmo ajudaria a gente a tentar discernir algo em cima dos dados. Eventualmente ajudando na an√°lise explorat√≥ria e indicando de que forma poder√≠amos anotar esses dados trasnformando o problema em um problema supervisionado em algum momento.
:::

## PCA

```{python}
import pandas as pd
import plotly.express as px
from sklearn.datasets import load_iris
from sklearn.decomposition import PCA

# Carregar um conjunto de dados de exemplo (Iris)
data = load_iris()
X = data.data
y = data.target
target_names = data.target_names

# Aplicar PCA para reduzir para 2 dimens√µes
pca = PCA(n_components=2)
X_pca = pca.fit_transform(X)

# Criar DataFrame para plotagem
df = pd.DataFrame({
    'PC1': X_pca[:, 0],
    'PC2': X_pca[:, 1],
    'Classe': [target_names[i] for i in y]
})

# Plot com Plotly
fig = px.scatter(
    df, x='PC1', y='PC2',
    color='Classe',
    title='PCA: Proje√ß√£o dos Dados nos Dois Primeiros Componentes',
    labels={'PC1': 'Componente Principal 1', 'PC2': 'Componente Principal 2'}
)
fig.show()

```

::: notes
O **PCA (An√°lise de Componentes Principais)** √© um algoritmo de aprendizado n√£o-supervisionado usado para reduzir a dimensionalidade dos dados, transformando vari√°veis originais em novas vari√°veis (componentes principais) que capturam a maior parte da vari√¢ncia presente nos dados, facilitando visualiza√ß√£o e an√°lise de padr√µes.
:::

## Aplica√ß√µes

-   Segmenta√ß√£o de clientes

-   Detec√ß√£o de anomalias

-   Agrupamento de textos

-   Descoberta de padr√µes de consumo (regras de associa√ß√£o)

## Aprendizagem por refor√ßo

![Genshin Impact](https://mygear.vn/media/lib/05-12-2022/ge4.jpg)

::: notes
Aprendizagem por refor√ßo √© uma t√©cnica em que um agente aprende a tomar decis√µes sequenciais ao interagir com um ambiente, recebendo recompensas ou puni√ß√µes para maximizar seu desempenho ao longo do tempo.
:::

## Aprendizagem por refor√ßo

![Aprendizagem por refor√ßo](imgs/reforco.png)

::: notes
Aprendizagem por refor√ßo √© uma t√©cnica em que um agente aprende a tomar decis√µes sequenciais ao interagir com um ambiente, recebendo recompensas ou puni√ß√µes para maximizar seu desempenho ao longo do tempo.
:::

## Perceptron

::: column-screen-inset
<iframe src="imgs/perceptron.html" width="2000px" height="600px">

</iframe>
:::

## Perceptron
$$
\hat{y} = f\left( \sum_{i=0}^{m} w_i x_i \right)
$$

## Redes Neurais Profundas

::: column-screen-inset
<iframe src="imgs/profunda.html" width="2000px" height="600px">

</iframe>
:::

## Treinando uma rede

::: column-screen-inset
<iframe src="imgs/rede_neural.html" width="2000px" height="600px">

</iframe>
:::


## Propaga√ß√£o 


| Id  | Idade | IMC  | Glicose | Press√£o | Diabetes üéØ |
|-----|-------|------|---------|---------|-------------|
| 1   | 45    | 29.0 | 130     | 80      | ‚úÖ Sim      |
| 2   | 34    | 22.5 | 98      | 70      | ‚ùå N√£o      |
| 3   | 54    | 31.2 | 145     | 85      | ‚úÖ Sim      |
| 4   | 29    | 24.1 | 92      | 75      | ‚ùå N√£o      |
| 5   | 62    | 33.8 | 160     | 90      | ‚úÖ Sim      |

## Retropropaga√ß√£o

::: column-screen-inset
<iframe src="imgs/retro.html" width="2000px" height="600px">

</iframe>
:::

## Arquiteturas de Redes Neurais

![https://www.asimovinstitute.org/neural-network-zoo/](https://www.asimovinstitute.org/wp-content/uploads/2019/04/NeuralNetworkZo19High.png)

## Redes Neurais Convolucionais (CNNs)

![](imgs/oia.png)

## Redes Neurais Convolucionais (CNNs)

![](imgs/oia_vermelho.png)

## Redes Neurais Convolucionais (CNNs)

![https://alexlenail.me/NN-SVG/LeNet.html](imgs/convolucional.png)

## Vis√£o Computacional para Ind√∫stria 4.0

![https://www.kaggle.com/datasets/salmaneunus/railway-track-fault-detection](imgs/trilho.jpg)

## Sa√∫de

![https://www.kaggle.com/datasets/paultimothymooney/chest-xray-pneumonia](imgs/medical.jpeg)

## Sustentabilidade e Meio Ambiente

![https://www.kaggle.com/datasets/akhilchibber/deforestation-detection-dataset](imgs/floresta.jpg)

## Detec√ß√£o de objetos - Agricultura

![https://www.kaggle.com/datasets/trainingdatapro/ripe-strawberries-detection](imgs/morangos.png)

## Segmenta√ß√£o de objetos

![https://www.sciencedirect.com/science/article/abs/pii/S0926985117307632](imgs/salt.jpg)

## Transfer√™ncia de aprendizado

![https://www.cs.toronto.edu/~kriz/cifar.html](imgs/cifar10.png)

## Transfer√™ncia de aprendizado

- Fine-tuning

::: notes

Como funciona: Um modelo pr√©-treinado em uma tarefa grande (ex: ImageNet para imagens, ou Wikipedia para texto) tem suas camadas finais ajustadas (ou toda a rede √© re-treinada com uma taxa de aprendizado menor) para uma nova tarefa espec√≠fica.
Exemplo: Pegar um ResNet treinado para classificar 1000 objetos e ajustar para detectar tipos de defeitos em pe√ßas industriais.

:::

## Transfer√™ncia de aprendizado

- Fine-tuning

- Transfer√™ncia de dom√≠nio 

::: notes

Como funciona: O modelo √© treinado em um dom√≠nio (ex: fotos de c√¢meras profissionais) e depois adaptado para outro (ex: imagens de celulares), geralmente usando t√©cnicas para reduzir a diferen√ßa entre os dom√≠nios.
Exemplo: Treinar um modelo de reconhecimento facial em fotos de est√∫dio e adapt√°-lo para funcionar em selfies.

:::

## Redes Neurais Recorrentes (RNNs)

::: column-screen-inset
<iframe src="imgs/rnn.html" width="2000px" height="600px">

</iframe>
:::

## Redes Neurais Recorrentes (RNNs)

 - LSTM (Long Short-Term Memory)

 - GRU ( Gated Recurrent Unit )

## S√©ries temporais

![https://www.kaggle.com/datasets/abhisheksjha/time-series-air-quality-data-of-india-2010-2023/data](imgs/timeseries.png)

## IoT e sensores

![](imgs/watch.jpg)

## Completa√ß√£o de texto ou c√≥digo

Time Series Air **Quality**

## Recursos

- [HuggingFace](https://huggingface.co)

- [Kaggle](https://www.kaggle.com)

- [PapersWithCode](https://paperswithcode.com)

## FrameWorks

- [TensorFlow](https://www.tensorflow.org)

- [Pytorch](https://pytorch.org)

- [HuggingFace](https://huggingface.co/docs)

- [Jax](https://docs.jax.dev/en/latest/quickstart.html)

## Intelig√™ncia Artificial Generativa

![IA Generativa](imgs/generativeai.png)


::: notes
Chegamos ent√£o √† Intelig√™ncia Artificial Generativa (Generative AI). Esta √© uma sub√°rea da IA focada na cria√ß√£o de modelos capazes de gerar conte√∫do novo e original que se assemelha aos dados com os quais foram treinados. Em vez de apenas classificar ou prever (IA discriminativa), a IA generativa cria. Isso pode incluir texto, imagens, m√∫sica, c√≥digo, v√≠deos, designs, estruturas moleculares, e mais. Ela aprende os padr√µes e a estrutura subjacente dos dados de treinamento e usa esse conhecimento para produzir novas amostras.
:::

## O que √© Generative AI?

 - Objetivo: Aprender a distribui√ß√£o de probabilidade dos dados de treinamento $P(\mathbf{x})$.
 - Tarefa: Gerar novas amostras $\mathbf{x}_{novo} \sim P(\mathbf{x})$ que sejam realistas e diversas.


## O que √© Generative AI?

 - Diferen√ßa para IA Discriminativa:
    - Discriminativa (ex: Classifica√ß√£o): Aprende $P(y|\mathbf{x})$ - a probabilidade da classe $y$ dado a entrada $\mathbf{x}$. Foco em mapear entrada para sa√≠da.
    - Generativa: Aprende $P(\mathbf{x})$ (ou $P(\mathbf{x}, y)$). Foco em entender como os dados s√£o gerados.
Tecnologias Chave: LLMs (Transformers), Modelos de Difus√£o, GANs, VAEs.

::: notes
Formalmente, o objetivo da IA Generativa √© aprender a distribui√ß√£o de probabilidade dos dados de treinamento. Uma vez que o modelo aprendeu essa distribui√ß√£o, ele pode "amostrar" dela para gerar novos dados que pare√ßam vir da mesma distribui√ß√£o. Isso contrasta com modelos discriminativos, que aprendem a separar diferentes tipos de dados (ex: classificar emails como spam ou n√£o spam) aprendendo a fronteira de decis√£o entre eles, sem necessariamente saber como gerar um email de spam ou n√£o spam. As tecnologias mais proeminentes hoje para IA Generativa incluem LLMs (baseados em Transformers), Modelos de Difus√£o e GANs.
:::

## Transformers

![Transformer](imgs/transformer.png)

::: notes
A arquitetura Transformer, introduzida no paper "Attention Is All You Need" (2017), revolucionou o processamento de linguagem natural e se expandiu para outras √°reas. Sua principal inova√ß√£o √© o mecanismo de auto-aten√ß√£o (self-attention). Diferente das RNNs que processam sequ√™ncias passo a passo (o que limita a paraleliza√ß√£o e dificulta capturar depend√™ncias longas), a aten√ß√£o permite que o modelo pondere a import√¢ncia de todas as outras palavras na sequ√™ncia ao processar uma palavra espec√≠fica, independentemente da dist√¢ncia. Isso permite capturar rela√ß√µes de longo alcance de forma eficiente e processar a sequ√™ncia em paralelo, levando a treinamentos mais r√°pidos e modelos mais poderosos.
:::

## Completa√ß√£o

Hoje acordei e

## Completa√ß√£o

\[Hoje\] \[acordei\] \[e\]

## Completa√ß√£o

\[Hoje\] \[acordei\] \[e\]

\[ca√≠ \] .9

\[ \] 0.01

\[ levantei \] 0.008


## Completa√ß√£o

\[Hoje\] \[acordei\] \[e\] \[ca√≠ \]

## Completa√ß√£o

\[Hoje\] \[acordei\] \[e\] \[ca√≠ \]

\[da \]  0.8

\[pizza \] 0.1

\[ gato \] 0.1

## Tokeniza√ß√£o

"O mundo √© redondo, mas est√° ficando cada mais quadrado."

## Byte Pair Encoding - Passo 1

Primeiro, dividimos o texto em palavras e adicionamos um s√≠mbolo especial ao final de cada palavra (por exemplo, </w> para indicar o fim da palavra):

"O</w> mundo</w> √©</w> redondo,</w> mas</w> est√°</w> ficando</w> cada</w> mais</w> quadrado.</w>
"

## Byte Pair Encoding - Passo 2

Cada palavra √© decomposta em caracteres (incluindo o s√≠mbolo de fim de palavra):

O </w>

m u n d o </w>

√© </w>

r e d o n d o , </w>

m a s </w>

e s t √° </w>

f i c a n d o </w>

c a d a </w>

m a i s </w>

q u a d r a d o . </w>


## Byte Pair Encoding - Passo 3

Agora, contamos todos os pares de caracteres adjacentes mais frequentes em todas as palavras. Exemplo: "m u", "u n", "n d", "d o" em "mundo".

## Byte Pair Encoding - Passo 4

Unimos o par mais frequente em um novo s√≠mbolo. Por exemplo, se "a s" aparece muito, vira "as". Repetimos esse processo v√°rias vezes.

Exemplo de itera√ß√µes (simplificado):

Itera√ß√£o 1: "a s" ‚Üí "as"

Itera√ß√£o 2: "m a" ‚Üí "ma"

Itera√ß√£o 3: "n d" ‚Üí "nd"

Itera√ß√£o 4: "d o" ‚Üí "do"
...


## Byte Pair Encoding - Passo 5

Depois de v√°rias jun√ß√µes, as palavras originais s√£o representadas como sequ√™ncias de subpalavras ou tokens BPE.

Exemplo (imaginando algumas jun√ß√µes):

"quadrado" pode virar: ["qua", "dra", "do", ". </w>"]

"ficando" pode virar: ["fi", "can", "do", "</w>"]

"redondo" pode virar: ["re", "don", "do", ", </w>"]

## Ra√≠zes das palavras

feliz ‚Üí ["feliz"]

felicidade ‚Üí ["feli", "cidade"]

infeliz ‚Üí ["in", "feliz"]

infelicidade ‚Üí ["in", "feli", "cidade"]

felizmente ‚Üí ["feliz", "mente"]

infelizmente ‚Üí ["in", "feliz", "mente"]

superfeliz ‚Üí ["super", "feliz"]

## Embeddings

| O   | mun | do | √© | re | don | do , | mas | es | t√° | fi | can | do | ca | da | vez | mais | qua | dra | do . | ... |
|-----|-----|----|---|----|-----|------|-----|----|----|----|-----|----|----|----|-----|------|-----|-----|------|-----|
| 0.3 | 0.2 | 0.4|0.2|0.6 | 0.5 | 0.3  | 0.4 |0.2 |0.5 |0.7 |0.3  |0.2 |0.4 |0.5 |0.6  | 0.9  |0.5  |0.4  |0.3   | ... |
| 0.7 | 0.8 | 0.1|0.9|0.3 | 0.7 | 0.2  | 0.8 |0.7 |0.2 |0.1 |0.8  |0.5 |0.3 |0.1 |0.2  | 0.1  |0.4  |0.2  |0.7   | ... |
| 0.2 | 0.4 | 0.3|0.7|0.7 | 0.6 | 0.8  | 0.6 |0.9 |0.4 |0.4 |0.2  |0.8 |0.7 |0.6 |0.9  | 0.4  |0.2  |0.5  |0.8   | ... |
| 0.5 | 0.1 | 0.7|0.1|0.2 | 0.3 | 0.4  | 0.2 |0.6 |0.1 |0.6 |0.5  |0.1 |0.8 |0.7 |0.1  | 0.8  |0.7  |0.3  |0.2   | ... |




## Embeddings

- Cada token √© representado por um vetor

[Projector TensorFlow](https://projector.tensorflow.org)

::: notes
Embeddings s√£o representa√ß√µes vetoriais densas e de baixa dimens√£o de itens discretos, como palavras, usu√°rios, produtos ou at√© mesmo n√≥s em um grafo. Em vez de representar uma palavra com um vetor esparso enorme (one-hot encoding), usamos um vetor denso de n√∫meros reais (ex: 300 dimens√µes). Esses vetores s√£o aprendidos (geralmente por redes neurais como Word2Vec, GloVe, ou como parte de modelos maiores como Transformers) de forma que itens semanticamente similares tenham vetores pr√≥ximos no espa√ßo vetorial. Por exemplo, os vetores para "rei" e "rainha" estar√£o pr√≥ximos, e a rela√ß√£o entre "rei" e "rainha" pode ser similar √† rela√ß√£o entre "homem" e "mulher" (capturada por opera√ß√µes vetoriais). Embeddings s√£o fundamentais para que modelos de ML/DL processem dados categ√≥ricos e textuais de forma eficaz. O TensorFlow Embedding Projector √© uma ferramenta fant√°stica para visualizar esses espa√ßos vetoriais.
:::

## Tradu√ß√£o

![https://jalammar.github.io/illustrated-transformer/](https://jalammar.github.io/images/t/The_transformer_encoders_decoders.png)

## Detalhando

![https://jalammar.github.io/illustrated-transformer/](https://jalammar.github.io/images/t/The_transformer_encoder_decoder_stack.png)

## Encoder

![https://jalammar.github.io/illustrated-transformer/](https://jalammar.github.io/images/t/Transformer_encoder.png)

## Arquitetura transformers

![Arquitetura](imgs/diagrama-7.webp)

## Aplica√ß√µes de Transformers

- Processamento de Linguagem Natural (NLP):
    - Tradu√ß√£o Autom√°tica (Google Translate)
    - Gera√ß√£o de Texto (GPT, Gemini, Llama, Claude - base das LLMs)
    - Sumariza√ß√£o de Texto
    - Respondendo Perguntas (Question Answering)
    - An√°lise de Sentimento
    - Classifica√ß√£o de Texto

## Aplica√ß√µes de Transformers

- Vis√£o Computacional:
    - Classifica√ß√£o de Imagens (Vision Transformer - ViT)
    - Detec√ß√£o de Objetos (DETR)
    - Segmenta√ß√£o de Imagens
    - Gera√ß√£o de Imagens (a partir de texto, combinado com outras t√©cnicas)

## Aplica√ß√µes de Transformers

- Outras √Åreas:
    - Previs√£o de S√©ries Temporais
    - Bioinform√°tica (AlphaFold - previs√£o de estrutura de prote√≠nas)
    - Sistemas de Recomenda√ß√£o
    - Processamento de √Åudio


## LLMs (Large Language Models)

- Defini√ß√£o: Modelos de linguagem baseados em Transformers com bilh√µes (ou trilh√µes) de par√¢metros, treinados em quantidades massivas de texto (internet, livros, etc.).

## LLMs (Large Language Models)


- Capacidades:
    - Compreens√£o e gera√ß√£o de texto coerente e contextualmente relevante.
    - Tradu√ß√£o, sumariza√ß√£o, resposta a perguntas.
    - Racioc√≠nio (limitado), escrita criativa, gera√ß√£o de c√≥digo.
    - Few-shot / Zero-shot learning: Capacidade de realizar tarefas para as quais n√£o foram explicitamente treinados, apenas com base na descri√ß√£o da tarefa ou poucos exemplos no prompt.

## LLMs (Large Language Models)

- Exemplos: GPT-4 (OpenAI), Gemini (Google), Llama 3 (Meta), Claude 3 (Anthropic).

::: notes
Os Large Language Models (LLMs) s√£o talvez o exemplo mais conhecido de IA Generativa atualmente. S√£o essencialmente modelos Transformer escalados para tamanhos enormes em termos de n√∫mero de par√¢metros e dados de treinamento. Esse escalonamento massivo levou a habilidades emergentes not√°veis, como a capacidade de seguir instru√ß√µes complexas, gerar texto muito fluente e realizar tarefas com pouca ou nenhuma exemplifica√ß√£o pr√©via (few-shot/zero-shot learning). Eles s√£o a base de chatbots como ChatGPT, Gemini e Claude.
:::

## GANs (Redes Generativas Adversariais)

![](imgs/gan_faces.png)

## GANs (Redes Generativas Adversariais)

![](imgs/gan.png)

## GANs (Redes Generativas Adversariais)

 - Conceito: Duas redes neurais competindo:
    - Gerador (Generator): Tenta criar dados sint√©ticos (ex: imagens falsas) que pare√ßam reais. Come√ßa a partir de um vetor de ru√≠do aleat√≥rio.
    - Discriminador (Discriminator): Tenta distinguir entre dados reais (do dataset de treino) e dados falsos (criados pelo Gerador). √â um classificador bin√°rio.

## GANs (Redes Generativas Adversariais)

- Treinamento Adversarial:
    - O Gerador aprende a enganar o Discriminador.
    - O Discriminador aprende a n√£o ser enganado.
    - Elas melhoram juntas em um jogo de "gato e rato".

## GANs (Redes Generativas Adversariais)

- Aplica√ß√µes: Gera√ß√£o de imagens realistas, style transfer, super-resolu√ß√£o, data augmentation.
- Desafios: Treinamento pode ser inst√°vel (mode collapse, non-convergence).

::: notes
As Redes Generativas Adversariais (Generative Adversarial Networks - GANs) foram uma das primeiras t√©cnicas a gerar imagens realistas. A ideia √© colocar duas redes em competi√ß√£o. O Gerador cria amostras falsas, e o Discriminador tenta identificar se uma amostra √© real ou falsa. O Gerador √© treinado para maximizar a probabilidade de o Discriminador classificar suas sa√≠das como reais, enquanto o Discriminador √© treinado para classificar corretamente. Esse processo adversarial for√ßa o Gerador a produzir amostras cada vez mais indistingu√≠veis das reais. Embora poderosas, as GANs podem ser dif√≠ceis de treinar.
:::

## VAEs

![VAE](imgs/vae.png)

## Modelos de Difus√£o

![U-NET](imgs/unet.png)

## Modelos de Difus√£o

- Conceito: Geram dados (principalmente imagens) aprendendo a reverter um processo de adi√ß√£o de ru√≠do.

## Modelos de Difus√£o


- Processo:
    - Forward Process (Noising): Gradualmente adiciona ru√≠do Gaussiano a uma imagem real ao longo de v√°rios passos, at√© que se torne puro ru√≠do.
    - Reverse Process (Denoising): Treina uma rede neural (geralmente uma U-Net) para prever e remover o ru√≠do adicionado em cada passo, come√ßando de um ru√≠do aleat√≥rio e gradualmente reconstruindo uma imagem coerente.

## Modelos de Difus√£o

- Qualidade: Produzem imagens de alt√≠ssima qualidade e realismo.
- Controle: Podem ser condicionados por texto (text-to-image) ou outras imagens.
- Exemplos: DALL-E 2/3, Stable Diffusion, Midjourney, Imagen.

::: notes
Os Modelos de Difus√£o se tornaram a t√©cnica dominante para gera√ß√£o de imagens de alta qualidade. A ideia central √© engenhosa: primeiro, eles aprendem como destruir sistematicamente a informa√ß√£o em uma imagem adicionando ru√≠do (processo forward, que √© f√°cil de definir). Depois, eles treinam uma rede neural para fazer o processo inverso: come√ßar com puro ru√≠do e, passo a passo, remover o ru√≠do de forma inteligente para gerar uma imagem realista (processo reverse, que √© dif√≠cil e requer aprendizado). Ao condicionar o processo de denoising a um prompt de texto, obtemos os poderosos modelos text-to-image.
:::



## Diferen√ßas entre LLMs, GANs e Modelos de Difus√£o

```Markdown
| Caracter√≠stica        | LLMs (Transformers)                   | Modelos de Difus√£o                            | GANs                                         |
|-----------------------|----------------------------------------|------------------------------------------------|----------------------------------------------|
| Dom√≠nio Principal     | Texto, C√≥digo                          | Imagens (alta qualidade), √Åudio                | Imagens, V√≠deo, Dados Tabulares              |
| Mecanismo Base        | Auto-aten√ß√£o, Predi√ß√£o Autoregressiva  | Revers√£o de processo de ru√≠do (Denoising)     | Competi√ß√£o Gerador vs Discriminador          |
| Qualidade (Imagem)    | N/A (para texto √© alta)                | Muito Alta                                     | Alta (mas pode ter artefatos)                |
| Estabilidade Treino   | Geralmente est√°vel (custoso)           | Geralmente est√°vel                             | Pode ser inst√°vel (mode collapse)            |
| Controle Gera√ß√£o      | Prompt de texto                        | Prompt de texto, Imagem                        | Vetor Latente, Condicionamento               |
| Velocidade Gera√ß√£o    | R√°pida (paraleliz√°vel)                 | Lenta (m√∫ltiplos passos de denoising)          | R√°pida (um passo do gerador)                 |
```

::: notes

Embora todos sejam modelos generativos, existem diferen√ßas importantes:

LLMs s√£o baseados em Transformers e dominam tarefas de texto devido √† sua capacidade de lidar com sequ√™ncias longas e aten√ß√£o.
Modelos de Difus√£o se destacam na gera√ß√£o de imagens de alta fidelidade, atrav√©s de um processo iterativo de denoising, mas podem ser lentos para gerar.
GANs usam um treinamento adversarial √∫nico, s√£o r√°pidas na gera√ß√£o (ap√≥s treinadas), mas podem ser inst√°veis para treinar e √†s vezes sofrem de "mode collapse" (geram pouca variedade). A escolha entre eles depende da tarefa, do tipo de dados e dos requisitos de qualidade e velocidade. 

:::



## Desafios e Limita√ß√µes da IA

Apesar dos avan√ßos impressionantes, a IA (incluindo ML, DL e Generativa) ainda enfrenta desafios significativos:

- Complexidade e Interpretabilidade ("Black Box")
- Vi√©s e Justi√ßa
- Privacidade e Seguran√ßa
- Robustez e Generaliza√ß√£o
 - √âtica e Impacto Social

::: notes
√â crucial reconhecer que a IA n√£o √© uma solu√ß√£o m√°gica e possui limita√ß√µes e desafios importantes. Ignorar esses desafios pode levar a falhas, injusti√ßas e consequ√™ncias negativas. Vamos abordar alguns dos principais.
:::


## IA Explic√°vel (XAI)

- Problema: Modelos complexos (Deep Learning, LLMs) funcionam como "caixas-pretas" - √© dif√≠cil entender por que eles tomam uma decis√£o espec√≠fica.
- Objetivo (XAI): Desenvolver t√©cnicas para tornar as previs√µes e decis√µes dos modelos de IA compreens√≠veis para humanos.

## IA Explic√°vel (XAI)

- Import√¢ncia:
    - Confian√ßa: Usu√°rios precisam confiar nas decis√µes (ex: diagn√≥stico m√©dico).
    - Debugging: Entender por que um modelo falha.
    - Justi√ßa (Fairness): Verificar se o modelo n√£o usa vieses indesejados.
    - Conformidade (Compliance): Regulamenta√ß√µes (como GDPR) podem exigir explicabilidade.
- T√©cnicas: SHAP, LIME, Mapas de Aten√ß√£o, Contrafactuais.

::: notes
Um grande desafio, especialmente com redes neurais profundas e LLMs, √© a falta de transpar√™ncia. Por que o modelo recomendou este produto? Por que ele negou o cr√©dito? Por que ele gerou essa resposta espec√≠fica? A IA Explic√°vel (XAI) busca responder a essas perguntas, fornecendo insights sobre o funcionamento interno dos modelos. Isso √© vital para construir confian√ßa, depurar erros, garantir a justi√ßa e cumprir regulamenta√ß√µes.
:::

## Vi√©s Algor√≠tmico

- Problema: Modelos de IA aprendem a partir de dados, e se os dados refletem vieses hist√≥ricos ou sociais (de g√™nero, ra√ßa, etc.), o modelo aprender√° e poder√° at√© amplificar esses vieses.

## Vi√©s Algor√≠tmico


- Consequ√™ncias: Resultados injustos ou discriminat√≥rios em √°reas cr√≠ticas como contrata√ß√£o, concess√£o de cr√©dito, reconhecimento facial, justi√ßa criminal.
- Fontes de Vi√©s: Dados de treinamento desbalanceados ou tendenciosos, escolhas de features, design do algoritmo.

## Vi√©s Algor√≠tmico

- Mitiga√ß√£o:
    - Curadoria cuidadosa e auditoria dos dados.
    - Uso de m√©tricas de justi√ßa (fairness metrics).
    - Algoritmos "conscientes da justi√ßa" (fairness-aware algorithms).
    - P√≥s-processamento das sa√≠das do modelo.

::: notes
O vi√©s algor√≠tmico √© uma preocupa√ß√£o s√©ria. Os modelos n√£o s√£o inerentemente neutros; eles refletem o mundo (e os dados) com os quais foram treinados. Se esses dados cont√™m preconceitos, o modelo os aprender√°. Isso pode levar a sistemas que perpetuam ou at√© pioram as desigualdades existentes. Combater o vi√©s exige um esfor√ßo consciente em todas as etapas do desenvolvimento do modelo, desde a coleta de dados at√© a avalia√ß√£o e o monitoramento cont√≠nuo.
:::

## Privacidade e Seguran√ßa

- Privacidade:
    - Dados de Treinamento: Modelos (especialmente LLMs) s√£o treinados com grandes volumes de dados, que podem conter informa√ß√µes pessoais ou sens√≠veis.
    - Risco de Memoriza√ß√£o: Modelos podem "memorizar" partes dos dados de treinamento e revel√°-las inadvertidamente em suas sa√≠das.

## Privacidade e Seguran√ßa

- Privacidade:
    - Ataques de Infer√™ncia: Tentativas de extrair informa√ß√µes privadas sobre os dados de treinamento a partir das previs√µes do modelo.
    - Solu√ß√µes: Privacidade Diferencial, Aprendizado Federado, Anonimiza√ß√£o de dados.

## Privacidade e Seguran√ßa

- Seguran√ßa:
    - Ataques Adversariais: Pequenas perturba√ß√µes (impercept√≠veis para humanos) na entrada podem fazer o modelo errar completamente (ex: classificar um sinal de "Pare" como "Limite de Velocidade").

## Privacidade e Seguran√ßa

- Seguran√ßa:
    - Envenenamento de Dados (Data Poisoning): Inserir dados maliciosos no conjunto de treinamento para corromper o modelo.
    - Roubo de Modelo: Extrair a funcionalidade de um modelo propriet√°rio atrav√©s de consultas.

::: notes
A IA tamb√©m levanta quest√µes significativas de privacidade e seguran√ßa. Como garantir que dados sens√≠veis usados no treinamento n√£o sejam expostos? Como proteger os modelos contra ataques maliciosos que visam engan√°-los ou roub√°-los? T√©cnicas como Privacidade Diferencial buscam proteger a privacidade individual nos dados, enquanto a pesquisa em seguran√ßa se concentra em tornar os modelos mais robustos contra ataques adversariais e outras amea√ßas.
:::

## Generaliza√ß√£o e Robustez dos Modelos

- Generaliza√ß√£o: A capacidade do modelo de performar bem em dados novos e n√£o vistos durante o treinamento. Um modelo que apenas memoriza os dados de treino (overfitting) n√£o generaliza bem.

## Generaliza√ß√£o e Robustez dos Modelos


- Robustez: A capacidade do modelo de manter seu desempenho mesmo quando confrontado com:
    - Pequenas Perturba√ß√µes: Como nos ataques adversariais.
    - Mudan√ßas na Distribui√ß√£o dos Dados (Domain Shift): O mundo real muda, e os dados podem come√ßar a parecer diferentes daqueles com os quais o modelo foi treinado (ex: um modelo treinado no ver√£o pode performar mal no inverno).

## Generaliza√ß√£o e Robustez dos Modelos

- Desafio: Modelos atuais, apesar de poderosos, podem ser fr√°geis e sens√≠veis a pequenas mudan√ßas ou a dados ligeiramente fora da distribui√ß√£o de treinamento.

::: notes
Um bom modelo de ML n√£o deve apenas acertar nos dados que viu, mas tamb√©m generalizar para novos dados. O overfitting (ajuste excessivo aos dados de treino) √© um problema cl√°ssico. Al√©m disso, a robustez √© crucial. Queremos modelos que n√£o sejam facilmente enganados por pequenas altera√ß√µes na entrada e que continuem funcionando razoavelmente bem mesmo quando os dados do mundo real mudam um pouco em rela√ß√£o aos dados de treinamento. Garantir generaliza√ß√£o e robustez ainda s√£o √°reas ativas de pesquisa.
:::



## Futuro do Machine Learning e IA Generativa

- Fundamentos Permanecem
- Converg√™ncia e Hibridiza√ß√£o
- Multimodalidade
- Efici√™ncia
- Racioc√≠nio, Planejamento e Ferramentas
- PINNs

::: notes

Fundamentos Permanecem: ML Cl√°ssico (supervisionado, n√£o-supervisionado) e Deep Learning (CNNs, RNNs, etc.) continuam sendo a base sobre a qual a IA Generativa √© constru√≠da. Entender esses fundamentos √© crucial.
Converg√™ncia e Hibridiza√ß√£o: Veremos mais modelos que combinam t√©cnicas (ex: LLMs usando ferramentas de ML cl√°ssico, modelos generativos para data augmentation em tarefas supervisionadas).
Multimodalidade: Modelos que entendem e geram m√∫ltiplos tipos de dados simultaneamente (texto, imagem, √°udio, v√≠deo) como Gemini, GPT-4V.
Efici√™ncia: Foco em modelos menores, mais r√°pidos e energeticamente eficientes (quantiza√ß√£o, destila√ß√£o, arquiteturas eficientes).
Racioc√≠nio, Planejamento e Ferramentas: LLMs evoluindo para al√©m da gera√ß√£o de texto, incorporando capacidades de racioc√≠nio mais complexas, planejamento e uso de ferramentas externas (calculadoras, APIs, busca na web, execu√ß√£o de c√≥digo) -> Agentes.
Personaliza√ß√£o Extrema: IA adaptada √†s necessidades e contextos individuais.
Governan√ßa e √âtica: Necessidade crescente de frameworks robustos para governan√ßa, √©tica e seguran√ßa em IA.
::: 




## Arquiteturas

-   [Flamingo](https://arxiv.org/abs/2204.14198)

-   [Perceiver IO](https://arxiv.org/abs/2107.14795)

-   [NVLM](https://arxiv.org/abs/2409.11402)

::: notes
Vamos olhar brevemente para algumas arquiteturas e t√©cnicas mais avan√ßadas que est√£o impulsionando a IA Generativa, particularmente em torno dos LLMs e da multimodalidade.
:::

## RAG

- Problema: LLMs "puros" podem alucinar (inventar fatos) e seu conhecimento √© limitado aos dados de treinamento (podem estar desatualizados).
- Solu√ß√£o RAG: Combina um LLM pr√©-treinado com um mecanismo de busca/recupera√ß√£o externo.

## RAG

- Processo:
    - Usu√°rio faz uma pergunta.
    - A pergunta √© usada para buscar documentos/trechos relevantes em uma base de conhecimento externa (ex: artigos, documentos internos, web).
    - Os trechos recuperados s√£o adicionados ao prompt original do usu√°rio.
    - O LLM gera a resposta baseado no prompt aumentado (pergunta + contexto recuperado).

## RAG


- Benef√≠cios: Reduz alucina√ß√µes, permite usar conhecimento atualizado ou espec√≠fico de um dom√≠nio, possibilita citar fontes.
- Componentes Chave: Retriever (busca vetorial √© comum), LLM.

::: notes
RAG (Retrieval-Augmented Generation) √© uma t√©cnica poderosa para melhorar a confiabilidade e a atualidade das respostas dos LLMs. Em vez de depender apenas do conhecimento interno do modelo (que pode ser limitado ou desatualizado), o RAG primeiro busca informa√ß√µes relevantes em uma base de dados externa (usando t√©cnicas de busca, muitas vezes baseadas em embeddings e vector stores). Essa informa√ß√£o recuperada √© ent√£o fornecida ao LLM junto com a pergunta original, dando-lhe o contexto necess√°rio para gerar uma resposta mais precisa e fundamentada. Isso √© crucial para aplica√ß√µes empresariais onde a precis√£o e a capacidade de citar fontes s√£o importantes.
:::

## Perguntas

![QR Code](imgs/qrcode.png)
