---
title: "&#8203;"
title-slide-attributes:
    data-background-image: imgs\title-slide.svg
    data-background-size: contain
    data-background-opacity: "1.0"
author: "&#8203;"
format: 
    revealjs:
        theme: [default, custom.scss]
        transition: fade
        slide-number: true
        preview-links: true
        incremental: true
        embed-resources: false
        notes: false
        self-contained-math: true
---

## ‚Äã

::: column-screen-inset
<iframe src="imgs/apresentacao.html" width="2000px" height="600px">

</iframe>
:::

## Pergunta

**Machine learning** e **deep learning** ainda s√£o relevantes na era das LLMs?

![](imgs/duvida.jpg)

::: notes
Para come√ßar essa apresenta√ß√£o eu vou come√ßar com uma pergunta. **Machine learning** e **deep learning** ainda s√£o relevantes na era das LLMs? Pra responder essa pergunta vamos partir do zero. Eu n√£o vou contar a hist√≥ria do machine learning aqui, mas n√≥s vamos entender qual a categoriza√ß√£o dessas coisas e que tipo de problemas que elas s√£o capazes de resolver.
:::

## Qual a organiza√ß√£o?

![](imgs/sequencia.svg){fig-align="center",width=270}

::: notes
O termo IA explodiu nos √∫ltimos anos e quando as pessoas est√£o falando de LLMs ou de IA generativa no geral elas utilizam o termo IA. Mas na pr√°tica intelig√™ncia artificial √© uma √°rea bem abrangente que engloba o machine learning, dentro do machine learning n√≥s m√©todos espec√≠ficos que envolvem redes neurais e como consequ√™ncia o deep learning. E as LLMs e geradores de imagem no geral s√£o modelos de deep learning treinados com um prop√≥sito espec√≠fico. Embora hoje em dia com uso de ferramentas, agentes e mem√≥ria e racioc√≠nio estejam tentando imitar o que seria o comportamento de uma IA uma intelig√™ncia artifical mais geral.
:::

## O que √© o machine learning?

| Renda Mensal (R\$) | Tempo de Relacionamento (meses) | Risco de Inadimpl√™ncia |
|-------------------|------------------------------|-----------------------|
| 2.500              | 8                               | Alto                   |
| 4.800              | 36                              | Baixo                  |
| 3.200              | 12                              | M√©dio                  |
| 8.500              | 60                              | Baixo                  |
| 1.800              | 3                               | Alto                   |
| 5.300              | 24                              | Baixo                  |

::: notes
Mas a ess√™ncia de tudo √© o machine learning. No machine learning n√≥s utilizamos t√©cnicas que permitem que os computadores aprendam sem serem explicitamente programados. Por exemplo, eu n√£o tenho uma regra pr√© definida que eu consiga aplicar pra resolver o problema dessa tabela de me dizer se o risco de inadinpl√™ncia de um cliente de um banco √© alto ou baixo. Por√©m, existem algoritmos que se eu passar cada um desses exemplos eles v√£o ser capazes de come√ßar a identificar padr√µes e posteriormente fazer a classifica√ß√£o dos clientes quando passar um cliente novo. Ou seja, o algoritmo n√£o apenas memorizar esses exemplos, mas tamb√©m vai generalizar de forma que quando eu passar um exemplo novo de clientes que tem caracter√≠sticas um pouquinho diferentes ele tamb√©m vai conseguir classificar os clientes.
:::

## Subdivis√µes do Machine learning

-   Aprendizado supervisionado

-   Aprendizado n√£o-supervisionado

-   Aprendizagem por refor√ßo

::: notes
E o machine learning pode ser subdividido em tr√™s categorias principais que seriam o Aprendizado supervisionado, Aprendizado n√£o-supervisionado, Aprendizagem por refor√ßo.
:::

------------------------------------------------------------------------

## Aprendizado supervisionado

::: column-screen-inset
<iframe src="imgs/supervisionado.html" width="2000px" height="600px">

</iframe>
:::

::: notes
No aprendizado supervisionado n√≥s temos ainda a regress√£o e a classifica√ß√£o. Na regress√£o o objetivo √© prever um valor cont√≠nuo e na classifica√ß√£o separar as classes como no exemplo que eu j√° citei.
:::

## Regress√£o {auto-animate="true"}

```{python}
import numpy as np
import pandas as pd
import plotly.express as px

# Par√¢metros
np.random.seed(42)
meses = pd.date_range(start='2022-01-01', end='2024-12-01', freq='MS')
n = len(meses)

# Tend√™ncia de crescimento linear
tendencia = np.linspace(10000, 40000, n)

# Sazonalidade anual (picos em dezembro)
sazonalidade = 5000 * np.sin(2 * np.pi * (meses.month - 1) / 12)

# Ru√≠do aleat√≥rio
ruido = np.random.normal(0, 1500, n)

# Receita simulada
receita = tendencia + sazonalidade + ruido

# DataFrame
df = pd.DataFrame({
    'M√™s': meses,
    'Receita Mensal (R$)': receita
})

# Gr√°fico
fig = px.scatter(df, x='M√™s', y='Receita Mensal (R$)', 
                 title='Receita Mensal de uma Loja Online (2022-2024)',
                 labels={'Receita Mensal (R$)': 'Receita Mensal (R$)'},
                 )

fig.update_traces(marker=dict(size=8, color='royalblue'))
fig.show()


```

::: notes
E a√≠ a regress√£o √© um √≥timo ponto de partida pra que n√≥s possamos come√ßar a entender como funciona a generaliza√ß√£o de um m√©todo de machine learning. Vamos pegar esse exemplo onde queremos em um dia x intermedi√°rio entre dezembro e janeiro de 2023.
:::

## Regress√£o {auto-animate="true"}

```{python}
import numpy as np
import pandas as pd
import plotly.express as px

# Par√¢metros
np.random.seed(42)
meses = pd.date_range(start='2022-01-01', end='2024-12-01', freq='MS')
n = len(meses)

# Tend√™ncia de crescimento linear
tendencia = np.linspace(10000, 40000, n)

# Sazonalidade anual (picos em dezembro)
sazonalidade = 5000 * np.sin(2 * np.pi * (meses.month - 1) / 12)

# Ru√≠do aleat√≥rio
ruido = np.random.normal(0, 1500, n)

# Receita simulada
receita = tendencia + sazonalidade + ruido

# DataFrame
df = pd.DataFrame({
    'M√™s': meses,
    'Receita Mensal (R$)': receita
})

# Gr√°fico
fig = px.scatter(df, x='M√™s', y='Receita Mensal (R$)', 
                 title='Receita Mensal de uma Loja Online (2022-2024)',
                 labels={'Receita Mensal (R$)': 'Receita Mensal (R$)'},
                 trendline="ols")

fig.update_traces(marker=dict(size=8, color='royalblue'))
for trace in fig.data:
    if trace.mode == 'lines':
        trace.line.color = 'red'
fig.show()


```

::: notes
Pra fazer isso eu posso muito bem ajustar uma reta a esses dados.
:::

## Regress√£o

::: fragment
$$
y = a \cdot x +b 
$$
:::

::: fragment
$$
y = 0.00028 \cdot x -452196 
$$
:::

::: notes
Quando eu ajusto uma reta aos dados eu estou calculando os coeficientes dessa reta. De forma que tendo os coeficientes eu consigo fazer uma estimativa dos valores intermedi√°rios ou at√© uma tentativa de extrapola√ß√£o fazendo uma proje√ß√£o da reta para o futuro. J√° que nesse caso nos estamos com um caso particular de regress√£o que envolve uma s√©rie temporal. Ou seja, ajustando a reta e determinando os coeficientes estamos conseguindo generalizar o problema e calcular o valor da receita mesmo em datas onde n√£o coletamos o valor da receita.
:::

## Regress√£o

```{python}
import numpy as np
import pandas as pd
import plotly.graph_objects as go

# Par√¢metros
np.random.seed(42)
meses = pd.date_range(start='2022-01-01', end='2024-12-01', freq='MS')
n = len(meses)

# Tend√™ncia de crescimento linear
tendencia = np.linspace(10000, 40000, n)

# Sazonalidade anual (picos em dezembro)
sazonalidade = 5000 * np.sin(2 * np.pi * (meses.month - 1) / 12)

# Ru√≠do aleat√≥rio
ruido = np.random.normal(0, 1500, n)

# Receita simulada
receita = tendencia + sazonalidade + ruido

# DataFrame
df = pd.DataFrame({
    'M√™s': meses,
    'Receita Mensal (R$)': receita
})

# Transformando a data em n√∫mero para ajuste polinomial
x = np.arange(n)  # pode ser dias ou meses, aqui estamos usando a posi√ß√£o do m√™s
y = receita

# Ajuste polinomial de grau 4 (voc√™ pode mudar para 3, 5, etc)
grau = 9
coef = np.polyfit(x, y, grau)
polinomio = np.poly1d(coef)

# Valores ajustados pelo polin√¥mio
y_fit = polinomio(x)

# Gr√°fico
fig = go.Figure()

# Pontos reais
fig.add_trace(go.Scatter(
    x=df['M√™s'], y=y, mode='markers',
    marker=dict(size=8, color='royalblue'),
    name='Receita Mensal'
))

# Curva polinomial ajustada
fig.add_trace(go.Scatter(
    x=df['M√™s'], y=y_fit, mode='lines',
    line=dict(color='red', width=3),
    name=f'Ajuste Polinomial (grau {grau})'
))

fig.update_layout(
    title='Receita Mensal de uma Loja Online (2022-2024) com Ajuste Polinomial',
    xaxis_title='M√™s',
    yaxis_title='Receita Mensal (R$)'
)

fig.show()

```

::: notes
√â claro que podemos ver que a reta talvez n√£o seja a melhor solu√ß√£o para esse caso. Poderia ajustar um polin√¥mio talvez.
:::

## Classifica√ß√£o

```{python}
import numpy as np
import pandas as pd
import plotly.express as px

np.random.seed(42)
n = 100
desconto = np.random.uniform(0, 50, n)

def sigmoid(x):
    return 1 / (1 + np.exp(-(x-25)/5))

prob_compra = sigmoid(desconto)
classe = np.random.binomial(1, prob_compra)

df = pd.DataFrame({'Desconto (%)': desconto, 'Comprou': classe})

# Converta a coluna para string para garantir que seja categ√≥rica
df['Comprou'] = df['Comprou'].astype(str)

fig = px.scatter(
    df, x='Desconto (%)', y='Comprou',
    color='Comprou',
    color_discrete_map={'0': 'red', '1': 'blue'},
    category_orders={'Comprou': ['1', '0']},  # Ordem correta: 0 embaixo, 1 em cima
    title='Probabilidade de Compra em Fun√ß√£o do Desconto',
    labels={'Comprou': 'Classe (0=N√£o comprou, 1=Comprou)'}
)

fig.update_traces(marker=dict(size=10, opacity=0.7, line=dict(width=1, color='black')))

fig.show()


```

::: notes
J√° a classifica√ß√£o em um primeiro momento √© um pouco mais dif√≠cil de pensar como um ajuste de curva aos dados porque estamos tentando separar duas classes diferentes.
:::

## Classifica√ß√£o

```{python}
import numpy as np
import pandas as pd
import plotly.express as px

np.random.seed(42)
n = 100
desconto = np.random.uniform(0, 50, n)

def sigmoid(x):
    return 1 / (1 + np.exp(-(x-25)/5))

prob_compra = sigmoid(desconto)
classe = np.random.binomial(1, prob_compra)

df = pd.DataFrame({'Desconto (%)': desconto, 'Comprou': classe})

fig = px.scatter(
    df, x='Desconto (%)', y='Comprou',
    color=df['Comprou'].astype(str),
    color_discrete_map={'0': 'red', '1': 'blue'},
    title='Probabilidade de Compra em Fun√ß√£o do Desconto',
    labels={'Comprou': 'Classe (0=N√£o comprou, 1=Comprou)'}
)
fig.update_traces(marker=dict(size=10, opacity=0.7, line=dict(width=1, color='black')))

# Adicionando a curva sigmoide
x_curve = np.linspace(0, 50, 200)
y_curve = sigmoid(x_curve)

fig.add_scatter(
    x=x_curve,
    y=y_curve,
    mode='lines',
    name='Curva Sigmoide',
    line=dict(color='black', width=3)
)

fig.show()



```

::: notes
Mas tamb√©m podemos ver o problema dessa forma. Nesse caso por exemplo podemos ajustar uma curva do tipo sigm√≥ide.
:::

## Classifica√ß√£o

```{python}
import numpy as np
import pandas as pd
import plotly.express as px

np.random.seed(42)
n = 100
desconto = np.random.uniform(0, 50, n)

def sigmoid(x):
    return 1 / (1 + np.exp(-(x-25)/5))

prob_compra = sigmoid(desconto)
classe = np.random.binomial(1, prob_compra)

df = pd.DataFrame({'Desconto (%)': desconto, 'Comprou': classe})

fig = px.scatter(
    df, x='Desconto (%)', y='Comprou',
    color=df['Comprou'].astype(str),
    color_discrete_map={'0': 'red', '1': 'blue'},
    title='Probabilidade de Compra em Fun√ß√£o do Desconto',
    labels={'Comprou': 'Classe (0=N√£o comprou, 1=Comprou)'}
)
fig.update_traces(marker=dict(size=10, opacity=0.7, line=dict(width=1, color='black')))

# Adicionando a curva sigmoide
x_curve = np.linspace(0, 50, 200)
y_curve = sigmoid(x_curve)

fig.add_scatter(
    x=x_curve,
    y=y_curve,
    mode='lines',
    name='Curva Sigmoide',
    line=dict(color='black', width=3)
)

# Adicionando a linha divis√≥ria em y=0.5
fig.add_shape(
    type="line",
    x0=0, x1=50,
    y0=0.5, y1=0.5,
    line=dict(color="green", width=2, dash="dash"),
    name='Divis√£o 0.5'
)

# Opcional: adicionar anota√ß√£o indicando o limiar
fig.add_annotation(
    x=2, y=0.52,
    text="Limiar 0.5",
    showarrow=False,
    font=dict(color="green", size=12),
    bgcolor="white"
)

fig.show()

```

::: notes
e depois definir em que n√≠vel de diferen√ßa dos valores da sigm√≥ide vamos separar os dados.
:::

## Classifica√ß√£o

\$\$ 

\sigma(\mathbf{x}) = \frac{1}{1 + e^{-(w^T \mathbf{x} + b)}}

\$\$

## Aprendizado supervisionado

[Scikit-learn](https://scikit-learn.org/stable/supervised_learning.html)

::: notes
√â claro que esses s√£o apenas alguns dos m√©todos dispon√≠veis para regress√£o e classifica√ß√£o se entrarmos por exemplo na p√°gina da sklearn vamos ver in√∫meros outros m√©todos que v√£o ser mais ou menos eficientes para se ajustar a tipos de dados diferentes de n tipos de problemas de regress√£o e classifica√ß√£o.
:::

## Aprendizado supervisionado

| Id  | Idade | IMC  | Glicose | Press√£o | Diabetes üéØ |
|-----|-------|------|---------|---------|-------------|
| 1   | 45    | 29.0 | 130     | 80      | ‚úÖ Sim      |
| 2   | 34    | 22.5 | 98      | 70      | ‚ùå N√£o      |
| 3   | 54    | 31.2 | 145     | 85      | ‚úÖ Sim      |
| 4   | 29    | 24.1 | 92      | 75      | ‚ùå N√£o      |
| 5   | 62    | 33.8 | 160     | 90      | ‚úÖ Sim      |

::: notes
Ainda nos problemas de apredizagem supervisionado, a caracter√≠stica mais importante √© que nesses problemas eu tenho um alvo. Por exemplo nesse caso eu tenho a classe se a pessoa tem ou n√£o diabetes, ou no problema financeiro de regress√£o eu tenho os valores monet√°rios para cada data. O que √© importante notar √© esses valores s√£o valores que aprenda de alguma forma a descobrir quando passo por exemplo as caracter√≠sticas do paciente ou do problema e pra que ele consiga aprender sobre o problema n√≥s precisamos ter esses valores registrados. Algu√©m precisou ir l√° entrevistar ou avaliar o caso de n pacientes e anotar os pacientes com as caracter√≠sticas x tem diabetes e os com as caracter√≠sticas y n√£o, depois os z tem...
:::

## Detec√ß√£o de fraude

![Rob√¥ cometendo fraude](imgs/fraude.png)

::: notes
Embora os dados tabulares sejam o exemplo mais simples de dados que n√≥s temos existem muitas aplica√ß√µes sobre esse tipo de dados. Um exemplo √© a detec√ß√£o de fraude. Modelos supervisionados (como Random Forest, XGBoost) treinados com hist√≥rico de transa√ß√µes rotuladas como ‚Äúfraudulentas‚Äù ou ‚Äúleg√≠timas‚Äù.
:::

## Previs√£o de churn

``` markdown
| customer_id | idade | tempo_de_contrato (meses) | valor_mensal | utilizacao_app (dias/m√™s) | reclamacoes | churn |
|-------------|-------|--------------------------|--------------|---------------------------|-------------|-------|
| 001         | 25    | 12                       | 79.90        | 22                        | 0           | 0     |
| 002         | 42    | 6                        | 99.90        | 10                        | 2           | 1     |
| 003         | 34    | 24                       | 59.90        | 25                        | 0           | 0     |
| 004         | 28    | 3                        | 89.90        | 5                         | 1           | 1     |
| 005         | 50    | 36                       | 49.90        | 30                        | 0           | 0     |
```

::: notes
Empresas de SaaS, telecom, bancos e varejo querem prever quais clientes est√£o propensos a cancelar seus servi√ßos.
:::

## Otimiza√ß√£o de cadeia de suprimentos

``` markdown
| produto_id | centro_distribuicao | estoque_atual | demanda_prevista | tempo_reposicao (dias) | custo_transporte | prioridade |
|------------|---------------------|---------------|------------------|-----------------------|------------------|------------|
| 1001       | SP                  | 150           | 200              | 2                     | 500              | 1          |
| 1002       | RJ                  | 80            | 60               | 3                     | 400              | 2          |
| 1003       | MG                  | 50            | 100              | 5                     | 700              | 1          |
| 1004       | RS                  | 200           | 180              | 4                     | 300              | 3          |
| 1005       | BA                  | 90            | 120              | 6                     | 600              | 2          |
```

::: notes
Previs√£o de demanda para estoques, log√≠stica e produ√ß√£o.
:::

## Aprendizado n√£o-supervisionado

| Id  | Idade | IMC  | Glicose | Press√£o |
|-----|-------|------|---------|---------|
| 1   | 45    | 29.0 | 130     | 80      |
| 2   | 34    | 22.5 | 98      | 70      |
| 3   | 54    | 31.2 | 145     | 85      |
| 4   | 29    | 24.1 | 92      | 75      |
| 5   | 62    | 33.8 | 160     | 90      |

::: notes
Mas eventualmente n√≥s nos deparamos com problemas que √© a primeira vez que n√≥s estamos vendo. N√≥s nem sequer sabemos que a diabetes existe, por exemplo. Mas a√≠ nos nossos registros m√©dicos vamos anotando os dados das pessoas e vamos percebendo algumas caracter√≠sticas.
:::

## Clustering

```{python}

import pandas as pd
import plotly.express as px
from sklearn.datasets import make_blobs

# Gerar dados sint√©ticos com 2 clusters
X, y = make_blobs(n_samples=100, centers=2, cluster_std=2.5, random_state=42)

# Ajustar os valores para simular IMC e Glicose em faixas realistas
# IMC: entre 18 e 40, Glicose: entre 70 e 200
IMC = 18 + (X[:, 0] - X[:, 0].min()) * (40 - 18) / (X[:, 0].max() - X[:, 0].min())
Glicose = 70 + (X[:, 1] - X[:, 1].min()) * (200 - 70) / (X[:, 1].max() - X[:, 1].min())

# Criar DataFrame
df = pd.DataFrame({
    'IMC': IMC,
    'Glicose': Glicose,
    'Grupo': ['Grupo 1' if label == 0 else 'Grupo 2' for label in y]
})

# Plot com Plotly
fig = px.scatter(
    df, x='IMC', y='Glicose',
    color='Grupo',
    title='Clustering Simulado: IMC vs Glicose',
    labels={'IMC': 'IMC', 'Glicose': 'Glicose'}
)
fig.show()



```

::: notes
E a√≠ um primeiro tipo de algoritmo bastanta conhecido seria um algoritmo de clustering e esse algoritmo ajudaria a gente a tentar discernir algo em cima dos dados. Eventualmente ajudando na an√°lise explorat√≥ria e indicando de que forma poder√≠amos anotar esses dados trasnformando o problema em um problema supervisionado em algum momento.
:::

## PCA

```{python}
import pandas as pd
import plotly.express as px
from sklearn.datasets import load_iris
from sklearn.decomposition import PCA

# Carregar um conjunto de dados de exemplo (Iris)
data = load_iris()
X = data.data
y = data.target
target_names = data.target_names

# Aplicar PCA para reduzir para 2 dimens√µes
pca = PCA(n_components=2)
X_pca = pca.fit_transform(X)

# Criar DataFrame para plotagem
df = pd.DataFrame({
    'PC1': X_pca[:, 0],
    'PC2': X_pca[:, 1],
    'Classe': [target_names[i] for i in y]
})

# Plot com Plotly
fig = px.scatter(
    df, x='PC1', y='PC2',
    color='Classe',
    title='PCA: Proje√ß√£o dos Dados nos Dois Primeiros Componentes',
    labels={'PC1': 'Componente Principal 1', 'PC2': 'Componente Principal 2'}
)
fig.show()

```

::: notes
O **PCA (An√°lise de Componentes Principais)** √© um algoritmo de aprendizado n√£o-supervisionado usado para reduzir a dimensionalidade dos dados, transformando vari√°veis originais em novas vari√°veis (componentes principais) que capturam a maior parte da vari√¢ncia presente nos dados, facilitando visualiza√ß√£o e an√°lise de padr√µes.
:::

## Aplica√ß√µes

-   Segmenta√ß√£o de clientes

-   Detec√ß√£o de anomalias

-   Agrupamento de textos

-   Descoberta de padr√µes de consumo (regras de associa√ß√£o)

## Aprendizagem por refor√ßo

![Genshin Impact](https://mygear.vn/media/lib/05-12-2022/ge4.jpg)

::: notes
Aprendizagem por refor√ßo √© uma t√©cnica em que um agente aprende a tomar decis√µes sequenciais ao interagir com um ambiente, recebendo recompensas ou puni√ß√µes para maximizar seu desempenho ao longo do tempo.
:::

## Aprendizagem por refor√ßo

![Aprendizagem por refor√ßo](imgs/reforco.png)

::: notes
Aprendizagem por refor√ßo √© uma t√©cnica em que um agente aprende a tomar decis√µes sequenciais ao interagir com um ambiente, recebendo recompensas ou puni√ß√µes para maximizar seu desempenho ao longo do tempo.
:::

## Perceptron

::: column-screen-inset
<iframe src="imgs/perceptron.html" width="2000px" height="600px">

</iframe>
:::

## Perceptron
$$
\hat{y} = f\left( \sum_{i=0}^{m} w_i x_i \right)
$$

## Redes Neurais Profundas

::: column-screen-inset
<iframe src="imgs/profunda.html" width="2000px" height="600px">

</iframe>
:::

## Treinando uma rede

::: column-screen-inset
<iframe src="imgs/rede_neural.html" width="2000px" height="600px">

</iframe>
:::


## Propaga√ß√£o 


| Id  | Idade | IMC  | Glicose | Press√£o | Diabetes üéØ |
|-----|-------|------|---------|---------|-------------|
| 1   | 45    | 29.0 | 130     | 80      | ‚úÖ Sim      |
| 2   | 34    | 22.5 | 98      | 70      | ‚ùå N√£o      |
| 3   | 54    | 31.2 | 145     | 85      | ‚úÖ Sim      |
| 4   | 29    | 24.1 | 92      | 75      | ‚ùå N√£o      |
| 5   | 62    | 33.8 | 160     | 90      | ‚úÖ Sim      |

## Retropropaga√ß√£o

::: column-screen-inset
<iframe src="imgs/retro.html" width="2000px" height="600px">

</iframe>
:::

## Arquiteturas de Redes Neurais

![https://www.asimovinstitute.org/neural-network-zoo/](https://www.asimovinstitute.org/wp-content/uploads/2019/04/NeuralNetworkZo19High.png)

## Redes Neurais Convolucionais (CNNs)

![](imgs/oia.png)

## Redes Neurais Convolucionais (CNNs)

![](imgs/oia_vermelho.png)

## Redes Neurais Convolucionais (CNNs)

![https://alexlenail.me/NN-SVG/LeNet.html](imgs/convolucional.png)

## Vis√£o Computacional para Ind√∫stria 4.0

![https://www.kaggle.com/datasets/salmaneunus/railway-track-fault-detection](imgs/trilho.jpg)

## Sa√∫de

![https://www.kaggle.com/datasets/paultimothymooney/chest-xray-pneumonia](imgs/medical.jpeg)

## Sustentabilidade e Meio Ambiente

![https://www.kaggle.com/datasets/akhilchibber/deforestation-detection-dataset](imgs/floresta.jpg)

## Detec√ß√£o de objetos - Agricultura

![https://www.kaggle.com/datasets/trainingdatapro/ripe-strawberries-detection](imgs/morangos.png)

## Segmenta√ß√£o de objetos

![https://www.sciencedirect.com/science/article/abs/pii/S0926985117307632](imgs/salt.jpg)

## Transfer√™ncia de aprendizado

![https://www.cs.toronto.edu/~kriz/cifar.html](imgs/cifar10.png)

## Transfer√™ncia de aprendizado

- Fine-tuning

::: notes

Como funciona: Um modelo pr√©-treinado em uma tarefa grande (ex: ImageNet para imagens, ou Wikipedia para texto) tem suas camadas finais ajustadas (ou toda a rede √© re-treinada com uma taxa de aprendizado menor) para uma nova tarefa espec√≠fica.
Exemplo: Pegar um ResNet treinado para classificar 1000 objetos e ajustar para detectar tipos de defeitos em pe√ßas industriais.

:::

## Transfer√™ncia de aprendizado

- Fine-tuning

- Transfer√™ncia de dom√≠nio 

::: notes

Como funciona: O modelo √© treinado em um dom√≠nio (ex: fotos de c√¢meras profissionais) e depois adaptado para outro (ex: imagens de celulares), geralmente usando t√©cnicas para reduzir a diferen√ßa entre os dom√≠nios.
Exemplo: Treinar um modelo de reconhecimento facial em fotos de est√∫dio e adapt√°-lo para funcionar em selfies.

:::

## Redes Neurais Recorrentes (RNNs)

::: column-screen-inset
<iframe src="imgs/rnn.html" width="2000px" height="600px">

</iframe>
:::

## Redes Neurais Recorrentes (RNNs)

 - LSTM (Long Short-Term Memory)

 - GRU ( Gated Recurrent Unit )

## S√©ries temporais

![https://www.kaggle.com/datasets/abhisheksjha/time-series-air-quality-data-of-india-2010-2023/data](imgs/timeseries.png)

## IoT e sensores

![](imgs/watch.jpg)

## Completa√ß√£o de texto ou c√≥digo

Time Series Air **Quality**

## Recursos

- [HuggingFace](https://huggingface.co)

- [Kaggle](https://www.kaggle.com)

- [PapersWithCode](https://paperswithcode.com)

## FrameWorks

- [TensorFlow](https://www.tensorflow.org)

- [Pytorch](https://pytorch.org)

- [HuggingFace](https://huggingface.co/docs)

- [Jax](https://docs.jax.dev/en/latest/quickstart.html)


## Transformers

## Aplica√ß√µes de Transformers

## Intelig√™ncia Artificial Generativa

## O que √© Generative AI?

## LLMs (Large Language Models)

## Modelos de Difus√£o

## GANs (Redes Generativas Adversariais)

## Diferen√ßas entre LLMs, GANs e Modelos de Difus√£o

## Aplica√ß√µes de IA Generativa

## Casos de Uso em Recomenda√ß√£o

## Casos de Uso em Predi√ß√£o

## Casos de Uso em Automa√ß√£o

## Casos de Uso em Cria√ß√£o de Conte√∫do

## Desafios e Limita√ß√µes da IA

## IA Explic√°vel (XAI)

## Vi√©s Algor√≠tmico

## Privacidade e Seguran√ßa

## Generaliza√ß√£o e Robustez dos Modelos

## Considera√ß√µes √âticas em IA

## Futuro do Machine Learning e IA Generativa


## IA Generativa

## Arquiteturas

-   [Flamingo](https://arxiv.org/abs/2204.14198)

-   [Perceiver IO](https://arxiv.org/abs/2107.14795)

-   [NVLM](https://arxiv.org/abs/2409.11402)

## RAG

Ingest√£o de documentos - [Docling](https://github.com/docling-project/docling)

## Vector Stores

[Vector Stores](https://docs.llamaindex.ai/en/stable/module_guides/storing/vector_stores/#vector-store-options--feature-support){.uri}

![](imgs/vector_stores.png)

::: notes
Os armazenamentos de vetores cont√™m vetores de incorpora√ß√£o de blocos de documentos ingeridos (e, √†s vezes, os blocos de documentos tamb√©m).
:::